---
type: lecture
date: 2026-01-12T10:00:00 EST
title: "Lecture 4: Distillation"
thumbnail: /static_files/presentations/lec4.png
slides: https://docs.google.com/presentation/d/1PinEgIptDA3AiAxERngTH3jqgxFwX3KA8edlh_97mYA/edit?usp=sharing
video: https://youtu.be/WNsdbrsUB-c
#panopto: https://mit.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=675d50ee-908e-4acc-a3d9-b24f012ed921
#feedback: https://docs.google.com/forms/d/e/1FAIpQLSdZAwGZHWHU-ivGeECkRLyo6qyb_eiNmobL1a6nVzqOu0EyRQ/viewform?usp=dialog
hide_from_announcements: true
---
 * What is the distillation of diffusion models?
   Fast, few-step generation with diffusion models.
 * New architectures and one-step distillation: Consistency Models and MeanFlow.

Suggested Readings:
 - [Rectified Flow](https://rectifiedflow.github.io/)
 - [Consistency models](https://arxiv.org/abs/2303.01469)
 - [Meanflow](https://arxiv.org/abs/2505.13447)
