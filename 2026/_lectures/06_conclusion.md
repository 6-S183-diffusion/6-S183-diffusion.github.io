---
type: lecture
date: 2026-01-16T10:00:00 EST
title: "Lecture 6: Model generalization, summary and conclusion"
thumbnail: /static_files/presentations/lec6.png
slides: https://docs.google.com/presentation/d/1LQSE9ezMuQc39ziKie7HxGArUYOe1zbBDXdwbezm8rE/edit?usp=sharing
video: https://youtu.be/50Ksf6NQE5c
hide_from_announcements: true
---

* Why do diffusion models generalize?
* Inductive biases of diffusion models: training and architecture.
* How to train better and focus on noise levels that matter most.

**Suggested Readings:**
 - [Interpreting and improving diffusion models from an optimization perspective](https://arxiv.org/pdf/2306.04848)
 - [Generalization in diffusion models arises from geometry-adaptive harmonic representations](https://arxiv.org/abs/2310.02557)
 - [Closed-Form Diffusion Models](https://arxiv.org/abs/2310.12395)
 - [Nuclear Norm Regularization for Deep Learning](https://arxiv.org/abs/2405.14544)
 - [An analytic theory of creativity in convolutional diffusion models](https://arxiv.org/abs/2412.20292)
